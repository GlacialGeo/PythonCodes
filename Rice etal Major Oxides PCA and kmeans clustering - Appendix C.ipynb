{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import gmean\n",
    "from sklearn.cluster import KMeans, k_means\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data and create a pandas dataframe. This uses a *.csv file and the example below is for a file located locally on the user's computer. \n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\...\\[Filename].csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() #To visualize the first 5 rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the columns that are not used in the PCA and kmeans analysis\n",
    "\n",
    "df2=df[df.columns[~df.columns.isin(['Sample','Latitude', 'Longitude', 'Easting', 'Northing'])]]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a numpy array from the new dataframe\n",
    "\n",
    "arr=df2.to_numpy()\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the number of elements in the array\n",
    "\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centred-log ratio transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the geometric mean of each row\n",
    "\n",
    "arr_2=gmean(arr, axis=1)\n",
    "arr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrT=arr.T               #Transpose matrix\n",
    "arrT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the clr transform\n",
    "\n",
    "arr_clr=np.log(arrT/arr_2)\n",
    "arr_clr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_clrT=arr_clr.T   #Transpose again to get back to the original array shape\n",
    "arr_clrT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_clrT.shape #Verify shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Analysis and kmeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X= arr_clrT\n",
    "\n",
    "# Preprocessing using scikit-learn tools\n",
    "Xs=StandardScaler().fit_transform(X) #Standardize the data to zero mean and unit variance\n",
    "\n",
    "print(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the results of the standardization\n",
    "\n",
    "SD_data = pd.DataFrame(Xs)\n",
    "print(SD_data)\n",
    "SD_data.to_csv(r'C:\\Users\\iamma\\Documents\\SD_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the 2D array into a 1D array\n",
    "Xs_flat = Xs.flatten()\n",
    "\n",
    "# Create histogram with optimal bin size to visualize the standardized data\n",
    "n, bins, patches = plt.hist(Xs_flat, bins='auto', density=True, alpha=0.9, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "# Add labels and title to plot\n",
    "plt.xlabel('z values')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bin_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Create a probability plot without a title and avoid the AttributeError with ppf\n",
    "fig, ax = plt.subplots()\n",
    "stats.probplot(Xs_flat, plot=ax)\n",
    "ax.set_title('')  # remove the default title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = X.shape[1]\n",
    "\n",
    "#Running PCA on all components\n",
    "pca=PCA(n_components=n_components, svd_solver='randomized')\n",
    "X_r=pca.fit(Xs).transform(Xs)\n",
    "\n",
    "#calculating the 95% variance\n",
    "total_variance = sum(pca.explained_variance_)\n",
    "print('Total variance in the dataset is:', total_variance)\n",
    "var_95 = total_variance*0.95\n",
    "print('The 95% variance is: ', var_95)\n",
    "print('')\n",
    "\n",
    "#Creating a df with the components and explained variance\n",
    "a = zip(range(0,n_components), pca.explained_variance_)\n",
    "a = pd.DataFrame(a, columns=['PCA Comp', 'Explained Variance'])\n",
    "\n",
    "#Trying to find 95%... \n",
    "print('Variance explained with 2 components:', sum(a['Explained Variance'][0:2]))\n",
    "print('Variance explained with 3 components:', sum(a['Explained Variance'][0:3]))\n",
    "print('Variance explained with 4 components:', sum(a['Explained Variance'][0:4]))\n",
    "print('Variance explained with 5 components:', sum(a['Explained Variance'][0:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cumulative sum of explained variance ratio\n",
    "cumulative_var_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# find the index where the cumulative sum first exceeds 0.95\n",
    "threshold_idx = np.where(cumulative_var_ratio >= 0.95)[0]\n",
    "\n",
    "if threshold_idx.size == 0:\n",
    "    # if no index is found, set the threshold index to the last index\n",
    "    threshold_idx = len(cumulative_var_ratio) - 1\n",
    "else:\n",
    "    # get the first index where the cumulative sum exceeds 0.95\n",
    "    threshold_idx = threshold_idx[0]\n",
    "\n",
    "#Make a scree plot\n",
    "fig, (ax1)=plt.subplots(1, figsize=(16,6))\n",
    "Xaxis=np.arange(len(a))\n",
    "ax1.plot(Xaxis,pca.explained_variance_ratio_, linewidth=2, c='r')\n",
    "ax1.set_xticks(Xaxis)\n",
    "ax1.set_xticklabels(Xaxis+1)\n",
    "plt.xlabel('n components')\n",
    "plt.ylabel('explained ratio')\n",
    "\n",
    "# add a horizontal dotted line at 95% explained variance ratio\n",
    "ax1.axhline(y=pca.explained_variance_ratio_[threshold_idx], linestyle=':', label='95% explained variance', c='blue')\n",
    "plt.legend(prop=dict(size=12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running PCA again, this time with 4 components\n",
    "\n",
    "pca=PCA(n_components=4, svd_solver='randomized')\n",
    "X_r2=pca.fit(Xs).transform(Xs)\n",
    "\n",
    "inertia=[]\n",
    "\n",
    "#Determining the nb# of kmeans clusters\n",
    "\n",
    "no_of_clusters=range(2,20) #[2,3,4,5...]\n",
    "Index=[]    #Creates an empty list\n",
    "\n",
    "for f in no_of_clusters:\n",
    "    kmeans = KMeans(n_clusters=f)\n",
    "    kmeans = kmeans.fit(X_r2)\n",
    "    u = kmeans.inertia_\n",
    "    inertia.append(u)\n",
    "    print('The inertia for :', f, 'clusters is', u)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a scree plot of inertia scores; the elbow method to detemrine the number of clusters. \n",
    "#In this case, there is a slight break in slope at 4 and 6 clusters\n",
    "\n",
    "fig, (ax1)=plt.subplots(1, figsize=(16,6))\n",
    "xx=np.arange(len(no_of_clusters))\n",
    "ax1.plot(xx, inertia)\n",
    "ax1.set_xticks(xx)\n",
    "ax1.set_xticklabels(no_of_clusters)\n",
    "plt.xlabel('Nb of clusters')\n",
    "plt.ylabel('Inertia score')\n",
    "plt.axvline(2, linestyle=':', color='green')   #plot a line for Nb. of clusters based on the 'elbow method'\n",
    "plt.axvline(4, linestyle=':', color='orange')\n",
    "plt.savefig('Screeplot.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another method to deterine the number of clusters (the Calinski-Harabasz score)\n",
    "\n",
    "no_of_clusters=range(2,20) #[2,3,4,5...]\n",
    "Index2=[]    #Creates an empty list\n",
    "\n",
    "for i in no_of_clusters:\n",
    "    kmeans=KMeans(n_clusters=i, random_state=2)\n",
    "    kmeans=kmeans.fit(X_r2)\n",
    "    CH=metrics.calinski_harabasz_score(X_r2, kmeans.labels_)\n",
    "    Index2.append(CH)   #This will populate the inertia list with u\n",
    "    print(\"The Calinski Harabasz score for :\", i, \"clusters is:\", CH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running K means on 6 clusters based on the two methods above as well as on local geological knowledge\n",
    "\n",
    "kmeans2=KMeans(n_clusters=6)\n",
    "kmeans2=kmeans2.fit(X_r2)\n",
    "\n",
    "\n",
    "clusters2=kmeans2.predict(X_r2)\n",
    "\n",
    "list_clusters=['Cluster 1','Cluster 2', 'Cluster 3', 'Cluster 4', 'Cluster 5', 'Cluster 6']\n",
    "\n",
    "#calculating the counts of the clusters\n",
    "unique, counts=np.unique(kmeans2.labels_, return_counts=True)\n",
    "counts=counts.reshape(1,6)   #one row and six columns\n",
    "\n",
    "#Creating a dataframe\n",
    "countscldf2=pd.DataFrame(counts, columns=list_clusters)\n",
    "\n",
    "#display\n",
    "countscldf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = pd.DataFrame(pca.components_.T, columns=['PC1', 'PC2', 'PC3', 'PC4'], index=['SiO2', 'Al2O3', 'Fe2O3','MgO','CaO','Na2O', 'K2O', 'TiO2', 'P2O5', 'MnO', 'Cr2O3'])\n",
    "loadings.index.name='Elements' #To name the index column\n",
    "loadings['Elements']=loadings.index    #the index is copied on to a new column with column name\n",
    "loadings = loadings.reset_index(drop=True) #the index replaced with sequence of numbers\n",
    "loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC1_sorted=loadings.sort_values(by=['PC1'])\n",
    "PC1_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar((PC1_sorted['Elements']), PC1_sorted['PC1'], linewidth=2., color='grey')\n",
    "plt.ylim((-0.7, 0.7)) \n",
    "plt.ylabel('PC 1 loadings', fontsize=15)\n",
    "plt.axhline(0,linestyle='-', c='black')\n",
    "plt.savefig('PC_loadings.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC2_sorted=loadings.sort_values(by=['PC2'])\n",
    "PC2_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar((PC2_sorted['Elements']), PC2_sorted['PC2'], linewidth=2., color='grey')\n",
    "plt.ylim((-0.8, 0.8)) \n",
    "plt.ylabel('PC 2 loadings', fontsize=15)\n",
    "plt.axhline(0,linestyle='-', c='black')\n",
    "#plt.savefig('PC_loadings.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_=pca.components_.copy()\n",
    "a_T=a_.T\n",
    "print(a_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_num = clusters2\n",
    "\n",
    "target_names = list_clusters\n",
    "\n",
    "PC1_Explained = pca.explained_variance_ratio_[0].round(4)*100\n",
    "PC2_Explained = pca.explained_variance_ratio_[1].round(4)*100\n",
    "PC3_Explained = pca.explained_variance_ratio_[2].round(4)*100\n",
    "\n",
    "#PLotting the data (pc1 V. pc2)\n",
    "plt.figure()\n",
    "plt.figure(figsize=(12,8))\n",
    "colors = ['black','blue', 'green', 'orange', 'red', 'brown']\n",
    "markers=['o','^','x', '.', 's', 'p']\n",
    "lw=2\n",
    "\n",
    "# Get the absolute maximum value of PC1 and PC2 scores\n",
    "PC1_abs_max = np.abs(X_r[:, 0]).max()\n",
    "PC2_abs_max = np.abs(X_r[:,1]).max()\n",
    "n = pca.components_.T.shape[0]\n",
    "\n",
    "#Assign both color and symbol to each cluster\n",
    "for color, i, marker, m, target_name in zip(colors, [0,1,2,3,4,5], markers, [0,1,2,3,4,5], target_names):\n",
    "    plt.scatter(X_r2[y_num == i, 0], X_r2[y_num == i, 1], color=color, marker=marker, alpha=.8, lw=lw, label=target_name)\n",
    "\n",
    "#Add the loading vectors scaled to the PC scores\n",
    "for l in range(n):\n",
    "    plt.quiver(0, 0, pca.components_.T[l,0]*PC1_abs_max, pca.components_.T[l,1]*PC2_abs_max,color = 'b',alpha = 0.5, width=0.002, headwidth=4, headlength=4, angles='xy', scale_units='xy', scale=1)\n",
    "\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.xlabel(f'PC 1 [{PC1_Explained:.2f}%]', fontsize=14) #using the .2f format specifier within the f-strings formats the floating-point numbers with two decimal places\n",
    "plt.ylabel(f'PC 2 [{PC2_Explained:.2f}%]', fontsize=14)\n",
    "plt.axvline(0,linestyle=':', c='black')\n",
    "plt.axhline(0, linestyle=':', c='black')\n",
    "\n",
    "\n",
    "plt.text(a_T[0,0]*PC1_abs_max, a_T[0,1]*PC2_abs_max, 'Si$O_2$')\n",
    "plt.text(a_T[1,0]*PC1_abs_max, a_T[1,1]*PC2_abs_max, '$Al_2$$O_3$')\n",
    "plt.text(a_T[2,0]*PC1_abs_max, a_T[2,1]*PC2_abs_max, '$Fe_2$$O_3$')\n",
    "plt.text(a_T[3,0]*PC1_abs_max, a_T[3,1]*PC2_abs_max, 'MgO')\n",
    "plt.text(a_T[4,0]*PC1_abs_max, a_T[4,1]*PC2_abs_max-0.2, 'CaO')\n",
    "plt.text(a_T[5,0]*PC1_abs_max, a_T[5,1]*PC2_abs_max, '$Na_2$O')\n",
    "plt.text(a_T[6,0]*PC1_abs_max, a_T[6,1]*PC2_abs_max, '$K_2$O')\n",
    "plt.text(a_T[7,0]*PC1_abs_max, a_T[7,1]*PC2_abs_max, 'Ti$O_2$')\n",
    "plt.text(a_T[8,0]*PC1_abs_max-0.5, a_T[8,1]*PC2_abs_max, '$P_2$$O_5$')\n",
    "plt.text(a_T[9,0]*PC1_abs_max, a_T[9,1]*PC2_abs_max, 'MnO')\n",
    "plt.text(a_T[10,0]*PC1_abs_max, a_T[10,1]*PC2_abs_max, '$Cr_2$$O_3$')\n",
    "\n",
    "plt.savefig('PC1_2_.png', format='png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLotting the data (pc1 v pc3)\n",
    "plt.figure()\n",
    "plt.figure(figsize=(12,8))\n",
    "colors = ['black','blue', 'green', 'orange', 'red', 'brown']\n",
    "markers=['o','^','x', '.', 's', 'p']\n",
    "lw=2\n",
    "\n",
    "# Get the absolute maximum value of PC1 and PC2 scores\n",
    "PC1_abs_max = np.abs(X_r[:, 0]).max()\n",
    "PC3_abs_max = np.abs(X_r[:,2]).max()\n",
    "n = pca.components_.T.shape[0]\n",
    "\n",
    "#Assign both color and symbol to each cluster\n",
    "for color, i, marker, m, target_name in zip(colors, [0,1,2,3,4,5], markers, [0,1,2,3,4,5], target_names):\n",
    "    plt.scatter(X_r2[y_num == i, 0], X_r2[y_num == i, 2], color=color, marker=marker, alpha=.8, lw=lw, label=target_name)\n",
    "\n",
    "#Add the loading vectors scaled to the PC scores\n",
    "for l in range(n):\n",
    "    plt.quiver(0, 0, pca.components_.T[l,0]*PC1_abs_max, pca.components_.T[l,2]*PC3_abs_max,color = 'b',alpha = 0.5, width=0.002, headwidth=4, headlength=4, angles='xy', scale_units='xy', scale=1)\n",
    "\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.6)  #This would used to put the legend outside the plot\n",
    "plt.xlabel(f'PC 1 [{PC1_Explained}%]', fontsize=14)\n",
    "plt.ylabel(f'PC 3 [{PC3_Explained}%]', fontsize=14)\n",
    "plt.axvline(0,linestyle=':', c='black')\n",
    "plt.axhline(0, linestyle=':', c='black')\n",
    "\n",
    "\n",
    "plt.text(a_T[0,0]*PC1_abs_max, a_T[0,2]*PC3_abs_max, 'Si$O_2$')\n",
    "plt.text(a_T[1,0]*PC1_abs_max, a_T[1,2]*PC3_abs_max, '$Al_2$$O_3$')\n",
    "plt.text(a_T[2,0]*PC1_abs_max, a_T[2,2]*PC3_abs_max, '$Fe_2$$O_3$')\n",
    "plt.text(a_T[3,0]*PC1_abs_max, a_T[3,2]*PC3_abs_max, 'MgO')\n",
    "plt.text(a_T[4,0]*PC1_abs_max, a_T[4,2]*PC3_abs_max, 'CaO')\n",
    "plt.text(a_T[5,0]*PC1_abs_max, a_T[5,2]*PC3_abs_max, '$Na_2$O')\n",
    "plt.text(a_T[6,0]*PC1_abs_max, a_T[6,2]*PC3_abs_max, '$K_2$O')\n",
    "plt.text(a_T[7,0]*PC1_abs_max, a_T[7,2]*PC3_abs_max, 'Ti$O_2$')\n",
    "plt.text(a_T[8,0]*PC1_abs_max, a_T[8,2]*PC3_abs_max, '$P_2$$O_5$')\n",
    "plt.text(a_T[9,0]*PC1_abs_max, a_T[9,2]*PC3_abs_max, 'MnO')\n",
    "plt.text(a_T[10,0]*PC1_abs_max, a_T[10,2]*PC3_abs_max, '$Cr_2$$O_3$')\n",
    "\n",
    "#plt.savefig('PC1_2_.pdf')\n",
    "#plt.savefig('PC1_2_.png', format='png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe of the PC scores\n",
    "\n",
    "df_PCscores=pd.DataFrame(X_r2, columns=['PC1', 'PC2', 'PC3', 'PC4'])\n",
    "df_PCscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert the kmeans labels into the new dataframe\n",
    "\n",
    "df_PCscores.insert(4, \"k_means_label\", kmeans2.labels_)\n",
    "#df_PCscores.insert(4, \"Sample\", df)\n",
    "df_PCscores.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert the sample numbers into the new dataframe\n",
    "\n",
    "extracted_col = df[\"Sample\"]\n",
    "  \n",
    "df_PCscores.insert(5, \"Sample\", extracted_col)\n",
    "\n",
    "df_PCscores.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the dataframe containing all results as a *.csv file for use externally such as to plot results in a GIS (for this, add the coordinates too)\n",
    "\n",
    "df_PCscores.to_csv('df_Rice_etal_Major_Oxides_PC_kmeans_.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
